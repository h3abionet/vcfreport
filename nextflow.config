/*
 * -------------------------------------------------
 * h3achipimputation Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */

// Global default params, used in configs
params {

  version = '1.0'
  container = 'docker://quay.io/h3abionet_org/imputation_tools:latest' // Container slug. Stable releases should specify release tag!
  clusterOptions = false
  help = false

  chromosomes = "ALL" // Impute all chromosomes by default
  project_name = "h3achipimputation" // Default project name

  // Minimac4 option
  minRatio = '0.01'
  chunk = ''

  outdir = "./"
}

profiles {

  standard {
    includeConfig 'conf/base.config'
  }
  conda { process.conda = "$baseDir/environment.yml" }
  docker {
    docker.enabled = true
    process.container = 'docker://quay.io/h3abionet_org/imputation_tools:latest'
  }
  singularity {
    singularity.enabled = true
    singularity.autoMounts = true
    process.container = 'docker://quay.io/h3abionet_org/imputation_tools:latest'
  }
  test {
    includeConfig 'conf/base.config'
    includeConfig 'conf/test.config'
  }
  slurm {
    includeConfig 'conf/base.config'
    process.executor = 'slurm'
  }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

manifest {
  name = 'h3achipimputation_evaluate_chips'
  description = 'imputation'
  homePage = 'https://github.com/h3abionet/chipimputation_evaluate_chips'
  mainScript = 'main.nf'
  version = '>=19.04.1'
}


timeline {
  enabled = true
  file = "${params.outdir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.outdir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.outdir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.outdir}/pipeline_dag.svg"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}

workflow.onComplete = {
  println "========================================="
  println "Pipeline completed at: $workflow.complete"
  println "Execution status: ${ workflow.success ? 'OK' : 'failed' }"
}
